{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeuroCodeInnovations/Estimacion_Peso_Cuyes/blob/main/ResNet50/ResNet50_Estimacion_Cuyes_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estimación del peso del cuy usando ResNet\n"
      ],
      "metadata": {
        "id": "gOloQjwmhwdg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalaciones previas"
      ],
      "metadata": {
        "id": "bD8p9HLEh-hA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Montar Google Drive"
      ],
      "metadata": {
        "id": "VrLAGqfaYU1W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZu7p0tlg60y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35d65b63-ee57-46df-fabc-1d304c7dfd58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importar librerias"
      ],
      "metadata": {
        "id": "w_SCgPfYR0mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "QApaEyuWR38X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargar e inspeccionar los datos"
      ],
      "metadata": {
        "id": "X7GiRGOOJ_Gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = '/content/drive/MyDrive/IMAG_CUYES/weights_train.txt'\n",
        "weights_df = pd.read_csv(weights_path, header=None, names=['filename', 'weight'])\n",
        "weights_df['weight'] = weights_df['weight'].astype(float)"
      ],
      "metadata": {
        "id": "nhVGIVLbJ-jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(weights_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxP5wee7KZ-X",
        "outputId": "75aded9b-ece9-4a09-989a-cf6e45b42b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              filename     weight\n",
            "0  B_CUY_01_001_01.jpg  308.44256\n",
            "1  B_CUY_01_001_02.jpg  308.44256\n",
            "2  B_CUY_01_001_03.jpg  308.44256\n",
            "3  B_CUY_01_001_04.jpg  308.44256\n",
            "4  B_CUY_01_001_05.jpg  308.44256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformar los datos\n",
        "Función para crear la clase DataSet de Pytorch para el entrenamiento"
      ],
      "metadata": {
        "id": "7af4VGtaSCVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GuineaPigDataset(Dataset):\n",
        "    def __init__(self, images_folder, weights_df, transform=None):\n",
        "        self.images_folder = images_folder\n",
        "        self.weights_df = weights_df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.weights_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.images_folder, self.weights_df.iloc[idx, 0])\n",
        "\n",
        "        # Verifica si el archivo existe\n",
        "        if not os.path.exists(img_name):\n",
        "            print(f\"Archivo no encontrado: {img_name}\")\n",
        "\n",
        "        image = Image.open(img_name).convert(\"RGB\")\n",
        "        weight = self.weights_df.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(weight, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "ZPZPKyU_Ib8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformación y carga de datos\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # ResNet espera imágenes de 256x256\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),  # Normalización para ResNet (Saber por qué)\n",
        "])\n",
        "\n",
        "# Dataset para el entrenamiento\n",
        "train_data = GuineaPigDataset('/content/drive/MyDrive/IMAG_CUYES/train', weights_df, transform=transform)\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "GqyKbKECO9ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modificar ResNet para regresión"
      ],
      "metadata": {
        "id": "LOt9zZTphmeQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaremos ResNet-50 y reemplazaremos la última capa para que tenga una salida única"
      ],
      "metadata": {
        "id": "1ZRhbgVExU_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "# Cargar el modelo preentrenado ResNet-50\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Modificar la última capa para regresión\n",
        "model.fc = nn.Linear(model.fc.in_features, 1)  # 1 salida para el peso"
      ],
      "metadata": {
        "id": "dMPOwgUgibLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47eb4850-f580-4088-95ba-d393636bd71d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 198MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurar el entrenamiento\n",
        "\n",
        "Definiremos el optimizador, la función de pérdida y el ciclo de entrenamiento. Para regresión, usamos el error cuadrático medio (MSE) como función de pérdida."
      ],
      "metadata": {
        "id": "vMWSqp2sxW2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Configurar el dispositivo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU disponible: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"No hay GPU disponible, se utilizará la CPU.\")\n",
        "\n",
        "# Definir la función de pérdida y el optimizador\n",
        "criterion = nn.MSELoss()  #(Error Cuadrático Medio) mide la diferencia promedio al cuadrado entre las predicciones del modelo y los valores reales.\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "NtBHnUPNxZx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34ceb8ce-d427-4de1-8648-b0a9c95b3707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU disponible: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenar el modelo\n",
        "\n"
      ],
      "metadata": {
        "id": "-OtmpedQ3S2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3  # Ajusta según el rendimiento y los recursos disponibles\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, weights in train_loader:\n",
        "        images, weights = images.to(device), weights.to(device).unsqueeze(1)  # Esto convierte weights de [batch] a [batch, 1]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, weights)\n",
        "\n",
        "        # Backward y optimización\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    # Guardar el modelo en cada época\n",
        "    torch.save(model.state_dict(), f'/content/drive/MyDrive/EPOCHS/02/weights_epoch_{epoch+1}.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dt6m2bw03TrT",
        "outputId": "72204e31-9f26-40ad-fd0b-123f78987352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Loss: 331307.6879\n",
            "Epoch [2/3], Loss: 95369.1348\n",
            "Epoch [3/3], Loss: 87576.6271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluar el modelo"
      ],
      "metadata": {
        "id": "KN4wM4Lb5lsY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar el modelo entrenado"
      ],
      "metadata": {
        "id": "VolwpJ6lUnor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Suponiendo que tu modelo se guarda como 'model.pth'\n",
        "model = models.resnet50(pretrained=False)  # Ajusta esto si usaste una arquitectura diferente\n",
        "num_classes = 1  # Cambia esto según el número de clases (en tu caso, pesos)\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# Carga los pesos del modelo\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/EPOCHS/02/weights_epoch_3.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrGi05wkUuCk",
        "outputId": "5410fcd6-045f-4bc3-a00e-c12c01414a58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-6-ef8c4c156b5c>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/drive/MyDrive/EPOCHS/02/weights_epoch_3.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparar las transformaciones de la imagen"
      ],
      "metadata": {
        "id": "1Y6yJ_rdUsxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),  # Ajusta el tamaño según el modelo\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Valores típicos para modelos preentrenados\n",
        "])"
      ],
      "metadata": {
        "id": "a-9ohxsoVGRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Función para evaluar y predecir"
      ],
      "metadata": {
        "id": "rP1RfcZhVSP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, image_folder):\n",
        "    predictions = []\n",
        "\n",
        "    for img_name in os.listdir(image_folder):\n",
        "        img_path = os.path.join(image_folder, img_name)\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = transform(img)\n",
        "        img = img.unsqueeze(0)  # Añadir dimensión de batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(img)\n",
        "            prediction = output.item()  # Obtener el valor escalar\n",
        "            predictions.append((img_name, prediction))\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "u4hqXOrNVTk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejecutar la evaluación\n",
        "\n",
        "Llama a la función y pasa la carpeta de imágenes de prueba."
      ],
      "metadata": {
        "id": "W8cdimQfVY3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = '/content/drive/MyDrive/IMAG_CUYES/test'\n",
        "predictions = evaluate_model(model, image_folder)\n",
        "\n",
        "# Convertir a un DataFrame para facilitar la visualización\n",
        "predictions_df = pd.DataFrame(predictions, columns=['Imagen', 'Predicción (gramos)'])\n",
        "print(predictions_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7opFQLRVuBf",
        "outputId": "e010ce82-6546-4c57-c05e-2268c7dfcfdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Imagen  Predicción (gramos)\n",
            "0    CUY_01_024_08.jpg           563.004883\n",
            "1    CUY_01_024_01.jpg           620.318359\n",
            "2    CUY_00_217_01.jpg           922.946777\n",
            "3    CUY_01_024_04.jpg           535.084106\n",
            "4    CUY_01_024_05.jpg           672.877136\n",
            "..                 ...                  ...\n",
            "450  CUY_01_035_01.jpg           599.757935\n",
            "451  CUY_01_026_13.jpg           538.565308\n",
            "452  CUY_01_026_11.jpg           528.808472\n",
            "453  CUY_01_026_03.jpg           663.990479\n",
            "454  CUY_01_035_05.jpg           708.845215\n",
            "\n",
            "[455 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluar la precisión\n",
        "\n",
        "Comparar las predicciones con los pesos reales para evaluar el rendimiento del modelo."
      ],
      "metadata": {
        "id": "Uy3XIEWhV0Gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar los pesos reales\n",
        "weights_df = pd.read_csv('/content/drive/MyDrive/IMAG_CUYES/weights_test.txt', sep=',', header=None, names=['Imagen', 'Peso'])\n",
        "merged_df = pd.merge(predictions_df, weights_df, on='Imagen', how='inner')\n",
        "merged_df['Error'] = merged_df['Predicción (gramos)'] - merged_df['Peso']\n",
        "\n",
        "print(merged_df.head())  # Muestra las primeras filas del DataFrame\n",
        "#print(merged_df.info())  # Información sobre el DataFrame (incluyendo conteo de nulos)"
      ],
      "metadata": {
        "id": "4s4xUpuP6w0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77aa6e6a-b7c8-4848-d777-773cb968a048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Imagen  Predicción (gramos)       Peso       Error\n",
            "0  CUY_01_024_08.jpg           563.004883   771.1064 -208.101517\n",
            "1  CUY_01_024_01.jpg           620.318359   771.1064 -150.788041\n",
            "2  CUY_00_217_01.jpg           922.946777  1014.0000  -91.053223\n",
            "3  CUY_01_024_04.jpg           535.084106   771.1064 -236.022294\n",
            "4  CUY_01_024_05.jpg           672.877136   771.1064  -98.229264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar los resultados de la prueba"
      ],
      "metadata": {
        "id": "_rhYA0QUa0Am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el DataFrame en un archivo .txt\n",
        "ruta = '/content/drive/MyDrive/RESULTADOS/02/resultados_errores.txt'\n",
        "merged_df.to_csv(ruta, sep='\\t', index=False)\n",
        "\n",
        "print(\"Archivo 'resultados_errores.txt' generado exitosamente.\")"
      ],
      "metadata": {
        "id": "qrk-y2Boa09F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e48292-d022-45d1-ebf8-7e9daba77efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo 'resultados_errores.txt' generado exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metricas"
      ],
      "metadata": {
        "id": "5MkW6y0XbCVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular métricas como el error cuadrático medio (RMSE)\n",
        "rmse = (merged_df['Error']**2).mean()**0.5\n",
        "print(f'RMSE: {rmse:.4f}')\n",
        "\n",
        "\n",
        "# Calculamos el MAE (Mean Absolute Error)\n",
        "mae = (merged_df['Predicción (gramos)'] - merged_df['Peso']).abs().mean()\n",
        "print(f'MAE: {mae:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IM97GP4W813",
        "outputId": "e47aa80c-1aee-4ecf-d341-712c2f0b19b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 285.6666\n",
            "MAE: 226.2983\n"
          ]
        }
      ]
    }
  ]
}